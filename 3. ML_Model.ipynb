{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Models\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import re\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_theme(palette=\"muted\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from scipy.stats import bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original dataset after ETL\n",
    "df = pd.read_csv('..\\\\datasets\\\\2. Processed Dataset\\\\result.csv')\n",
    "df = df.drop(columns=[\"id\"], errors=\"ignore\")\n",
    "# PCA dataset + One-Hotenconded\n",
    "df_pca = pd.read_csv('..\\\\datasets\\\\2. Processed Dataset\\\\pca_result.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## First approach models training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "MAE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RMSE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "%RMSE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "R²",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "8cc4c599-ae1a-44fe-a945-b245010e803a",
       "rows": [
        [
         "Linear Regression",
         "9579.996904680178",
         "13087.342629155648",
         "13.079736478051565",
         "0.9261954552205888"
        ],
        [
         "Random Forest",
         "7737.373188405798",
         "11778.308811930647",
         "11.771463450033073",
         "0.9402213594329735"
        ],
        [
         "XGBoost",
         "8030.985945991848",
         "12429.488261571276",
         "12.422264444747428",
         "0.9334287582343533"
        ],
        [
         "Neural Network",
         "9782.02077469693",
         "12843.88160485022",
         "12.836416949341636",
         "0.928915854345425"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>%RMSE</th>\n",
       "      <th>R²</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>9579.996905</td>\n",
       "      <td>13087.342629</td>\n",
       "      <td>13.079736</td>\n",
       "      <td>0.926195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>7737.373188</td>\n",
       "      <td>11778.308812</td>\n",
       "      <td>11.771463</td>\n",
       "      <td>0.940221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>8030.985946</td>\n",
       "      <td>12429.488262</td>\n",
       "      <td>12.422264</td>\n",
       "      <td>0.933429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural Network</th>\n",
       "      <td>9782.020775</td>\n",
       "      <td>12843.881605</td>\n",
       "      <td>12.836417</td>\n",
       "      <td>0.928916</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MAE          RMSE      %RMSE        R²\n",
       "Linear Regression  9579.996905  13087.342629  13.079736  0.926195\n",
       "Random Forest      7737.373188  11778.308812  11.771463  0.940221\n",
       "XGBoost            8030.985946  12429.488262  12.422264  0.933429\n",
       "Neural Network     9782.020775  12843.881605  12.836417  0.928916"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split of the dataset into features and target\n",
    "X = df_pca\n",
    "y = df['Salary'] \n",
    "\n",
    "# Split data into training and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state=0) # 25% test\n",
    "\n",
    "# Standardize Salary\n",
    "scaler_y = MinMaxScaler()\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1)).ravel()\n",
    "y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1)).ravel()\n",
    "\n",
    "# Initialize and train models\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=0),\n",
    "    \"XGBoost\": XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=0),\n",
    "    \"Neural Network\": MLPRegressor(hidden_layer_sizes=(64, 32), max_iter=500, random_state=0)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train_scaled)  # Train\n",
    "    y_pred_scaled = model.predict(X_test)  # Predict\n",
    "    y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).ravel()  # Inverse scale\n",
    "\n",
    "    # Compute metrics\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = root_mean_squared_error(y_test, y_pred)\n",
    "    rmse_percentage = (rmse / y_test.mean()) * 100\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    results[name] = {\"MAE\": mae, \"RMSE\": rmse, \"%RMSE\": rmse_percentage, \"R²\": r2}\n",
    "\n",
    "# Display results\n",
    "pd.DataFrame(results).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Model Hyperparameter Tunning with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split of the dataset into features and target\n",
    "X = df_pca\n",
    "y = df['Salary'] \n",
    "\n",
    "# Split data into training and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "\n",
    "# Standardize Salary\n",
    "scaler_y = MinMaxScaler()\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1)).ravel()\n",
    "y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1)).ravel()\n",
    "\n",
    "\n",
    "# Hyperparameter grids\n",
    "param_grids = {\n",
    "    \"Linear Regression\": {},\n",
    "    \"Random Forest\": {\n",
    "        \"n_estimators\": [100, 200, 300],\n",
    "        \"max_depth\": [2, 4, 8, 10, 20, None],\n",
    "        \"min_samples_split\": [2, 5, 10, 20]  \n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        \"n_estimators\": [50, 100, 200],\n",
    "        \"max_depth\": [3, 6, 10],\n",
    "        \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "    },\n",
    "    \"Neural Network\": {\n",
    "        'hidden_layer_sizes': [(64,), (128, 64), (64, 32)],\n",
    "        'alpha': [0.0001, 0.001, 0.01],\n",
    "        'learning_rate_init': [0.001, 0.01, 0.1]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    \"Linear Regression\":LinearRegression(),\n",
    "    \"Random Forest\": RandomForestRegressor(random_state=0),\n",
    "    \"XGBoost\": XGBRegressor(random_state=0),\n",
    "    \"Neural Network\": MLPRegressor(max_iter=500, random_state=0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best params for Linear Regression: {}\n",
      "✅ Best params for Random Forest: {'max_depth': 8, 'min_samples_split': 10, 'n_estimators': 300}\n",
      "✅ Best params for XGBoost: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "✅ Best params for Neural Network: {'alpha': 0.01, 'hidden_layer_sizes': (64, 32), 'learning_rate_init': 0.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "MAE",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "RMSE",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "%RMSE",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "R²",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "52ff4e26-3ede-4e2f-9400-5eaacaa7649b",
       "rows": [
        [
         "0",
         "Linear Regression",
         "9580.00",
         "13087.34",
         "13.08 ",
         "0.93 "
        ],
        [
         "1",
         "Random Forest",
         "8281.45",
         "12637.87",
         "12.63 ",
         "0.93 "
        ],
        [
         "2",
         "XGBoost",
         "8645.05",
         "12102.86",
         "12.10 ",
         "0.94 "
        ],
        [
         "3",
         "Neural Network",
         "6906.78",
         "9880.52",
         "9.87 ",
         "0.96 "
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>%RMSE</th>\n",
       "      <th>R²</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>9580.00</td>\n",
       "      <td>13087.34</td>\n",
       "      <td>13.08</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>8281.45</td>\n",
       "      <td>12637.87</td>\n",
       "      <td>12.63</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>8645.05</td>\n",
       "      <td>12102.86</td>\n",
       "      <td>12.10</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>6906.78</td>\n",
       "      <td>9880.52</td>\n",
       "      <td>9.87</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model      MAE      RMSE   %RMSE     R²\n",
       "0  Linear Regression  9580.00  13087.34  13.08   0.93 \n",
       "1      Random Forest  8281.45  12637.87  12.63   0.93 \n",
       "2            XGBoost  8645.05  12102.86  12.10   0.94 \n",
       "3     Neural Network  6906.78   9880.52   9.87   0.96 "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train models with hyperparameter tuning\n",
    "best_models = {}\n",
    "for name, model in models.items():\n",
    "    if name in param_grids:\n",
    "        search = GridSearchCV(model, param_grids[name], cv=5, scoring=\"neg_root_mean_squared_error\", n_jobs=-1)\n",
    "        search.fit(X_train, y_train_scaled)  # \n",
    "        best_models[name] = search.best_estimator_\n",
    "        print(f\"✅ Best params for {name}: {search.best_params_}\")\n",
    "    else:\n",
    "        model.fit(X_train, y_train_scaled)\n",
    "        best_models[name] = model\n",
    "\n",
    "\n",
    "# Compute and display model metrics\n",
    "results = []\n",
    "for name, model in best_models.items():\n",
    "    y_pred_scaled = model.predict(X_test)\n",
    "    y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).ravel()\n",
    "\n",
    "    # Compute metrics   \n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = root_mean_squared_error(y_test, y_pred)\n",
    "    rmse_percentage = (rmse / y_test.mean()) * 100\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"MAE\": f\"{mae:.2f}\",\n",
    "        \"RMSE\": f\"{rmse:.2f}\",\n",
    "        \"%RMSE\": f\"{rmse_percentage:.2f} \",\n",
    "        \"R²\": f\"{r2:.2f} \",\n",
    "    })\n",
    "\n",
    "# Display results in table format\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Overfitting Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Training vs. Test Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Performance:\n",
      "Train R²: 0.92 | Test R²: 0.93\n",
      "Train RMSE: 13623.02 | Test RMSE: 13087.34\n",
      "--------------------------------------------------\n",
      "Random Forest Performance:\n",
      "Train R²: 0.97 | Test R²: 0.93\n",
      "Train RMSE: 8432.13 | Test RMSE: 12637.87\n",
      "--------------------------------------------------\n",
      "XGBoost Performance:\n",
      "Train R²: 0.98 | Test R²: 0.94\n",
      "Train RMSE: 7306.06 | Test RMSE: 12102.86\n",
      "--------------------------------------------------\n",
      "Neural Network Performance:\n",
      "Train R²: 0.95 | Test R²: 0.96\n",
      "Train RMSE: 10943.24 | Test RMSE: 9880.52\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, X_train, y_train, X_test, y_test, model_name):\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Inverse scale predictions\n",
    "    y_train_pred = scaler_y.inverse_transform(y_train_pred.reshape(-1, 1)).ravel()\n",
    "    y_test_pred = scaler_y.inverse_transform(y_test_pred.reshape(-1, 1)).ravel()\n",
    "\n",
    "    print(f\"{model_name} Performance:\")\n",
    "    print(f\"Train R²: {r2_score(y_train, y_train_pred):.2f} | Test R²: {r2_score(y_test, y_test_pred):.2f}\")\n",
    "    print(f\"Train RMSE: {root_mean_squared_error(y_train, y_train_pred):.2f} | Test RMSE: {root_mean_squared_error(y_test, y_test_pred):.2f}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Apply this function to all trained models\n",
    "for name, model in best_models.items():\n",
    "    evaluate_model(model, X_train, y_train, X_test, y_test, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Cross-Validation:\n",
      "Cross-Validation R²: 0.90 ± 0.05\n",
      "--------------------------------------------------\n",
      "Random Forest Cross-Validation:\n",
      "Cross-Validation R²: 0.89 ± 0.07\n",
      "--------------------------------------------------\n",
      "XGBoost Cross-Validation:\n",
      "Cross-Validation R²: 0.90 ± 0.05\n",
      "--------------------------------------------------\n",
      "Neural Network Cross-Validation:\n",
      "Cross-Validation R²: 0.92 ± 0.03\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "y_scaled = scaler_y.fit_transform(y.values.reshape(-1, 1)).ravel()\n",
    "\n",
    "def cross_validate_model(model, X, y, cv=5):\n",
    "    \"\"\" Realiza validación cruzada y muestra los resultados de R² \"\"\"\n",
    "    scores = cross_val_score(model, X, y, cv=cv, scoring='r2', n_jobs=-1)\n",
    "    mean_r2, std_r2 = scores.mean(), scores.std()\n",
    "    print(f\"Cross-Validation R²: {mean_r2:.2f} ± {std_r2:.2f}\")\n",
    "\n",
    "# Aplicar validación cruzada en los mejores modelos\n",
    "for name, model in best_models.items():\n",
    "    print(f\"{name} Cross-Validation:\")\n",
    "    cross_validate_model(model, X, y_scaled)\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "- Linear Regression\n",
    "    - Train R²: 0.92 | Test R²: 0.93 - Train and Test R² are close what suggest is doing a good generalization.\n",
    "    - RMSE values are also close → No large performance drop.\n",
    "    - Cross-validation confirms stability (0.90 ± 0.05)\n",
    "    \n",
    "- Random Forest: \n",
    "    - Train R²: 0.97 | Test R²: 0.93 - R2 Train is much grater than Test R2, the model is overfitting.\n",
    "    - Train RMSE (8432.13) vs Test RMSE (12637.87) - Large gap suggests overfitting\n",
    "    \n",
    "- XGBoost\n",
    "    - Train R²: 0.98 | Test R²: 0.94 and Train RMSE: 7306.06 | Test RMSE: 12102.86 the model is overfitting.\n",
    "    - Cross-validation is stable (0.90 ± 0.05)\n",
    "    - Second best model with a slight overfitting bus stable performance.\n",
    "\n",
    "- Neural Network:\n",
    "    - Train R²: 0.95 | Test R²: 0.96 and Train RMSE: 10943.24 | Test RMSE: 9880.52 shows a balance model and no major overfitting despite being a more complex model.\n",
    "    - Cross-Validation shows highest mean R² (0.92) with lowest variance (±0.03) suggesting a strong generalization to unseen data.\n",
    "    - Best overall model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Model: {'MAE': 40690.50882167612, 'RMSE': 48180.83218379831, 'R2': -0.00029651269527053437}\n",
      "Random Forest Model: {'MAE': 8187.810127674259, 'RMSE': 13129.306241630149, 'R2': 0.9257213986110274}\n",
      "95% Confidence Intervals: {'MAE': (6309.50532694962, 10553.800724637682), 'RMSE': (9490.532520796181, 16744.374987512587), 'R2': (0.8704464400847671, 0.9602581561171868)}\n"
     ]
    }
   ],
   "source": [
    "# Confidence Intervals\n",
    "boot_metrics = {\"MAE\": [], \"RMSE\": [], \"R2\": []}\n",
    "num_bootstrap = 1000\n",
    "\n",
    "for _ in range(num_bootstrap):\n",
    "    indices = np.random.choice(len(y_test), size=len(y_test), replace=True)\n",
    "    y_test_sample = y_test.iloc[indices]\n",
    "    y_pred_sample = y_pred_rf[indices]\n",
    "    metrics = compute_metrics(y_test_sample, y_pred_sample)\n",
    "    for key in boot_metrics:\n",
    "        boot_metrics[key].append(metrics[key])\n",
    "\n",
    "ci_95 = {metric: (np.percentile(values, 2.5), np.percentile(values, 97.5)) for metric, values in boot_metrics.items()}\n",
    "\n",
    "# Print results\n",
    "print(\"Dummy Model:\", results_dummy)\n",
    "print(\"Random Forest Model:\", results_rf)\n",
    "print(\"95% Confidence Intervals:\", ci_95)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
